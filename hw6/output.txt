Task 1:
[epoch 01: iter 00100]    loss: 0.730
[epoch 01: iter 00200]    loss: 0.751
[epoch 01: iter 00300]    loss: 0.738
[epoch 01: iter 00400]    loss: 0.736
[epoch 01: iter 00500]    loss: 0.737
[epoch 01: iter 00600]    loss: 0.735
[epoch 01: iter 00700]    loss: 0.739
[epoch 01: iter 00800]    loss: 0.735
[epoch 01: iter 00900]    loss: 0.733
[epoch 01: iter 01000]    loss: 0.732
[epoch 01: iter 01100]    loss: 0.730
[epoch 01: iter 01200]    loss: 0.729
[epoch 01: iter 01300]    loss: 0.726
[epoch 01: iter 01400]    loss: 0.726
[epoch 01: iter 01500]    loss: 0.725
[epoch 01: iter 01600]    loss: 0.724
[epoch 01: iter 01700]    loss: 0.722
[epoch 01: iter 01800]    loss: 0.722
[epoch 02: iter 00100]    loss: 0.681
[epoch 02: iter 00200]    loss: 0.684
[epoch 02: iter 00300]    loss: 0.682
[epoch 02: iter 00400]    loss: 0.686
[epoch 02: iter 00500]    loss: 0.686
[epoch 02: iter 00600]    loss: 0.687
[epoch 02: iter 00700]    loss: 0.690
[epoch 02: iter 00800]    loss: 0.689
[epoch 02: iter 00900]    loss: 0.688
[epoch 02: iter 01000]    loss: 0.688
[epoch 02: iter 01100]    loss: 0.688
[epoch 02: iter 01200]    loss: 0.688
[epoch 02: iter 01300]    loss: 0.686
[epoch 02: iter 01400]    loss: 0.687
[epoch 02: iter 01500]    loss: 0.687
[epoch 02: iter 01600]    loss: 0.684
[epoch 02: iter 01700]    loss: 0.683
[epoch 02: iter 01800]    loss: 0.683
[epoch 03: iter 00100]    loss: 0.641
[epoch 03: iter 00200]    loss: 0.645
[epoch 03: iter 00300]    loss: 0.642
[epoch 03: iter 00400]    loss: 0.643
[epoch 03: iter 00500]    loss: 0.638
[epoch 03: iter 00600]    loss: 0.634
[epoch 03: iter 00700]    loss: 0.638
[epoch 03: iter 00800]    loss: 0.636
[epoch 03: iter 00900]    loss: 0.634
[epoch 03: iter 01000]    loss: 0.633
[epoch 03: iter 01100]    loss: 0.632
[epoch 03: iter 01200]    loss: 0.632
[epoch 03: iter 01300]    loss: 0.629
[epoch 03: iter 01400]    loss: 0.629
[epoch 03: iter 01500]    loss: 0.628
[epoch 03: iter 01600]    loss: 0.623
[epoch 03: iter 01700]    loss: 0.620
[epoch 03: iter 01800]    loss: 0.619
[epoch 04: iter 00100]    loss: 0.566
[epoch 04: iter 00200]    loss: 0.565
[epoch 04: iter 00300]    loss: 0.569
[epoch 04: iter 00400]    loss: 0.569
[epoch 04: iter 00500]    loss: 0.560
[epoch 04: iter 00600]    loss: 0.553
[epoch 04: iter 00700]    loss: 0.556
[epoch 04: iter 00800]    loss: 0.554
[epoch 04: iter 00900]    loss: 0.550
[epoch 04: iter 01000]    loss: 0.549
[epoch 04: iter 01100]    loss: 0.545
[epoch 04: iter 01200]    loss: 0.544
[epoch 04: iter 01300]    loss: 0.540
[epoch 04: iter 01400]    loss: 0.538
[epoch 04: iter 01500]    loss: 0.535
[epoch 04: iter 01600]    loss: 0.529
[epoch 04: iter 01700]    loss: 0.525
[epoch 04: iter 01800]    loss: 0.524
[epoch 05: iter 00100]    loss: 0.479
[epoch 05: iter 00200]    loss: 0.472
[epoch 05: iter 00300]    loss: 0.476
[epoch 05: iter 00400]    loss: 0.474
[epoch 05: iter 00500]    loss: 0.461
[epoch 05: iter 00600]    loss: 0.452
[epoch 05: iter 00700]    loss: 0.453
[epoch 05: iter 00800]    loss: 0.449
[epoch 05: iter 00900]    loss: 0.445
[epoch 05: iter 01000]    loss: 0.441
[epoch 05: iter 01100]    loss: 0.435
[epoch 05: iter 01200]    loss: 0.432
[epoch 05: iter 01300]    loss: 0.427
[epoch 05: iter 01400]    loss: 0.424
[epoch 05: iter 01500]    loss: 0.421
[epoch 05: iter 01600]    loss: 0.414
[epoch 05: iter 01700]    loss: 0.408
[epoch 05: iter 01800]    loss: 0.406
[epoch 06: iter 00100]    loss: 0.361
[epoch 06: iter 00200]    loss: 0.356
[epoch 06: iter 00300]    loss: 0.352
[epoch 06: iter 00400]    loss: 0.344
[epoch 06: iter 00500]    loss: 0.333
[epoch 06: iter 00600]    loss: 0.323
[epoch 06: iter 00700]    loss: 0.322
[epoch 06: iter 00800]    loss: 0.319
[epoch 06: iter 00900]    loss: 0.315
[epoch 06: iter 01000]    loss: 0.310
[epoch 06: iter 01100]    loss: 0.304
[epoch 06: iter 01200]    loss: 0.298
[epoch 06: iter 01300]    loss: 0.295
[epoch 06: iter 01400]    loss: 0.293
[epoch 06: iter 01500]    loss: 0.289
[epoch 06: iter 01600]    loss: 0.284
[epoch 06: iter 01700]    loss: 0.278
[epoch 06: iter 01800]    loss: 0.276
            negative  positive
  negative    70.903    26.633
  positive    42.475    61.122
Task 3:
[epoch 01: iter 00100]    loss: 0.730
[epoch 01: iter 00200]    loss: 0.751
[epoch 01: iter 00300]    loss: 0.738
[epoch 01: iter 00400]    loss: 0.736
[epoch 01: iter 00500]    loss: 0.737
[epoch 01: iter 00600]    loss: 0.735
[epoch 01: iter 00700]    loss: 0.739
[epoch 01: iter 00800]    loss: 0.735
[epoch 01: iter 00900]    loss: 0.733
[epoch 01: iter 01000]    loss: 0.732
[epoch 01: iter 01100]    loss: 0.730
[epoch 01: iter 01200]    loss: 0.729
[epoch 01: iter 01300]    loss: 0.726
[epoch 01: iter 01400]    loss: 0.726
[epoch 01: iter 01500]    loss: 0.725
[epoch 01: iter 01600]    loss: 0.724
[epoch 01: iter 01700]    loss: 0.722
[epoch 01: iter 01800]    loss: 0.722
[epoch 02: iter 00100]    loss: 0.681
[epoch 02: iter 00200]    loss: 0.684
[epoch 02: iter 00300]    loss: 0.682
[epoch 02: iter 00400]    loss: 0.686
[epoch 02: iter 00500]    loss: 0.686
[epoch 02: iter 00600]    loss: 0.687
[epoch 02: iter 00700]    loss: 0.690
[epoch 02: iter 00800]    loss: 0.689
[epoch 02: iter 00900]    loss: 0.688
[epoch 02: iter 01000]    loss: 0.688
[epoch 02: iter 01100]    loss: 0.688
[epoch 02: iter 01200]    loss: 0.688
[epoch 02: iter 01300]    loss: 0.686
[epoch 02: iter 01400]    loss: 0.687
[epoch 02: iter 01500]    loss: 0.687
[epoch 02: iter 01600]    loss: 0.684
[epoch 02: iter 01700]    loss: 0.683
[epoch 02: iter 01800]    loss: 0.683
[epoch 03: iter 00100]    loss: 0.641
[epoch 03: iter 00200]    loss: 0.645
[epoch 03: iter 00300]    loss: 0.642
[epoch 03: iter 00400]    loss: 0.643
[epoch 03: iter 00500]    loss: 0.638
[epoch 03: iter 00600]    loss: 0.634
[epoch 03: iter 00700]    loss: 0.638
[epoch 03: iter 00800]    loss: 0.636
[epoch 03: iter 00900]    loss: 0.634
[epoch 03: iter 01000]    loss: 0.633
[epoch 03: iter 01100]    loss: 0.632
[epoch 03: iter 01200]    loss: 0.632
[epoch 03: iter 01300]    loss: 0.629
[epoch 03: iter 01400]    loss: 0.629
[epoch 03: iter 01500]    loss: 0.628
[epoch 03: iter 01600]    loss: 0.623
[epoch 03: iter 01700]    loss: 0.620
[epoch 03: iter 01800]    loss: 0.619
[epoch 04: iter 00100]    loss: 0.566
[epoch 04: iter 00200]    loss: 0.565
[epoch 04: iter 00300]    loss: 0.569
[epoch 04: iter 00400]    loss: 0.569
[epoch 04: iter 00500]    loss: 0.560
[epoch 04: iter 00600]    loss: 0.553
[epoch 04: iter 00700]    loss: 0.556
[epoch 04: iter 00800]    loss: 0.554
[epoch 04: iter 00900]    loss: 0.550
[epoch 04: iter 01000]    loss: 0.549
[epoch 04: iter 01100]    loss: 0.545
[epoch 04: iter 01200]    loss: 0.544
[epoch 04: iter 01300]    loss: 0.540
[epoch 04: iter 01400]    loss: 0.538
[epoch 04: iter 01500]    loss: 0.535
[epoch 04: iter 01600]    loss: 0.529
[epoch 04: iter 01700]    loss: 0.525
[epoch 04: iter 01800]    loss: 0.524
[epoch 05: iter 00100]    loss: 0.479
[epoch 05: iter 00200]    loss: 0.472
[epoch 05: iter 00300]    loss: 0.476
[epoch 05: iter 00400]    loss: 0.474
[epoch 05: iter 00500]    loss: 0.461
[epoch 05: iter 00600]    loss: 0.452
[epoch 05: iter 00700]    loss: 0.453
[epoch 05: iter 00800]    loss: 0.449
[epoch 05: iter 00900]    loss: 0.445
[epoch 05: iter 01000]    loss: 0.441
[epoch 05: iter 01100]    loss: 0.435
[epoch 05: iter 01200]    loss: 0.432
[epoch 05: iter 01300]    loss: 0.427
[epoch 05: iter 01400]    loss: 0.424
[epoch 05: iter 01500]    loss: 0.421
[epoch 05: iter 01600]    loss: 0.414
[epoch 05: iter 01700]    loss: 0.408
[epoch 05: iter 01800]    loss: 0.406
[epoch 06: iter 00100]    loss: 0.361
[epoch 06: iter 00200]    loss: 0.356
[epoch 06: iter 00300]    loss: 0.352
[epoch 06: iter 00400]    loss: 0.344
[epoch 06: iter 00500]    loss: 0.333
[epoch 06: iter 00600]    loss: 0.323
[epoch 06: iter 00700]    loss: 0.322
[epoch 06: iter 00800]    loss: 0.319
[epoch 06: iter 00900]    loss: 0.315
[epoch 06: iter 01000]    loss: 0.310
[epoch 06: iter 01100]    loss: 0.304
[epoch 06: iter 01200]    loss: 0.298
[epoch 06: iter 01300]    loss: 0.295
[epoch 06: iter 01400]    loss: 0.293
[epoch 06: iter 01500]    loss: 0.289
[epoch 06: iter 01600]    loss: 0.284
[epoch 06: iter 01700]    loss: 0.278
[epoch 06: iter 01800]    loss: 0.276
            negative  positive
  negative    70.903    26.633
  positive    42.475    61.122
